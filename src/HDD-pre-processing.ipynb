{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "008c765d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pandas_profiling as pp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298bb58c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Original atts:\n",
    "age; sex (1,0); cp (1-4); trestbps; chol; fbs (1,0); restecg (0,1,2); thalach; exang (1,0); oldpeak; slope (1,2,3); ca; thal (3,6,7); class att: 0 is healthy, 1,2,3,4 is sick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f0cfa755",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    age  sex  chest_pain_type  resting_blood_pressure  cholesterol  \\\n0  63.0  1.0              1.0                   145.0        233.0   \n1  67.0  1.0              4.0                   160.0        286.0   \n2  67.0  1.0              4.0                   120.0        229.0   \n3  37.0  1.0              3.0                   130.0        250.0   \n4  41.0  0.0              2.0                   130.0        204.0   \n\n   fasting_blood_sugar  resting_electrocardiographic  max_heart_rate_achieved  \\\n0                  1.0                           2.0                    150.0   \n1                  0.0                           2.0                    108.0   \n2                  0.0                           2.0                    129.0   \n3                  0.0                           0.0                    187.0   \n4                  0.0                           2.0                    172.0   \n\n   exercise_induced_angina  ST_depression_induced_by_exercise  \\\n0                      0.0                                2.3   \n1                      1.0                                1.5   \n2                      1.0                                2.6   \n3                      0.0                                3.5   \n4                      0.0                                1.4   \n\n   peak_exercise_st_slope major_vessels_count thalassemia  target  \n0                     3.0                 0.0         6.0       0  \n1                     2.0                 3.0         3.0       2  \n2                     2.0                 2.0         7.0       1  \n3                     3.0                 0.0         3.0       0  \n4                     1.0                 0.0         3.0       0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>chest_pain_type</th>\n      <th>resting_blood_pressure</th>\n      <th>cholesterol</th>\n      <th>fasting_blood_sugar</th>\n      <th>resting_electrocardiographic</th>\n      <th>max_heart_rate_achieved</th>\n      <th>exercise_induced_angina</th>\n      <th>ST_depression_induced_by_exercise</th>\n      <th>peak_exercise_st_slope</th>\n      <th>major_vessels_count</th>\n      <th>thalassemia</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>63.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>145.0</td>\n      <td>233.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>150.0</td>\n      <td>0.0</td>\n      <td>2.3</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>67.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>160.0</td>\n      <td>286.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>108.0</td>\n      <td>1.0</td>\n      <td>1.5</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>67.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>120.0</td>\n      <td>229.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>129.0</td>\n      <td>1.0</td>\n      <td>2.6</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>7.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>37.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>130.0</td>\n      <td>250.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>187.0</td>\n      <td>0.0</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>41.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>130.0</td>\n      <td>204.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>172.0</td>\n      <td>0.0</td>\n      <td>1.4</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hd = pd.read_csv('../data/processed.cleveland.data', header=None)\n",
    "hd.columns = [\"age\", \"sex\", \"chest_pain_type\", \"resting_blood_pressure\", \"cholesterol\", \"fasting_blood_sugar\", \"resting_electrocardiographic\", \"max_heart_rate_achieved\", \"exercise_induced_angina\", \"ST_depression_induced_by_exercise\", \"peak_exercise_st_slope\", \"major_vessels_count\", \"thalassemia\", \"target\"]\n",
    "\n",
    "# TODO: Ask Bernat at what point do we split off our data for testing? Do we need to run our test data through pre-processing \"on it's own\"? If using jupyter, this means I am passing the data through the same statements as before, seems redundant and unnecessary.\n",
    "hd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bd6ea5c7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(303, 14)"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "data": {
      "text/plain": "              age         sex  chest_pain_type  resting_blood_pressure  \\\ncount  303.000000  303.000000       303.000000              303.000000   \nmean    54.438944    0.679868         3.158416              131.689769   \nstd      9.038662    0.467299         0.960126               17.599748   \nmin     29.000000    0.000000         1.000000               94.000000   \n25%     48.000000    0.000000         3.000000              120.000000   \n50%     56.000000    1.000000         3.000000              130.000000   \n75%     61.000000    1.000000         4.000000              140.000000   \nmax     77.000000    1.000000         4.000000              200.000000   \n\n       cholesterol  fasting_blood_sugar  resting_electrocardiographic  \\\ncount   303.000000           303.000000                    303.000000   \nmean    246.693069             0.148515                      0.990099   \nstd      51.776918             0.356198                      0.994971   \nmin     126.000000             0.000000                      0.000000   \n25%     211.000000             0.000000                      0.000000   \n50%     241.000000             0.000000                      1.000000   \n75%     275.000000             0.000000                      2.000000   \nmax     564.000000             1.000000                      2.000000   \n\n       max_heart_rate_achieved  exercise_induced_angina  \\\ncount               303.000000               303.000000   \nmean                149.607261                 0.326733   \nstd                  22.875003                 0.469794   \nmin                  71.000000                 0.000000   \n25%                 133.500000                 0.000000   \n50%                 153.000000                 0.000000   \n75%                 166.000000                 1.000000   \nmax                 202.000000                 1.000000   \n\n       ST_depression_induced_by_exercise  peak_exercise_st_slope      target  \ncount                         303.000000              303.000000  303.000000  \nmean                            1.039604                1.600660    0.937294  \nstd                             1.161075                0.616226    1.228536  \nmin                             0.000000                1.000000    0.000000  \n25%                             0.000000                1.000000    0.000000  \n50%                             0.800000                2.000000    0.000000  \n75%                             1.600000                2.000000    2.000000  \nmax                             6.200000                3.000000    4.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>chest_pain_type</th>\n      <th>resting_blood_pressure</th>\n      <th>cholesterol</th>\n      <th>fasting_blood_sugar</th>\n      <th>resting_electrocardiographic</th>\n      <th>max_heart_rate_achieved</th>\n      <th>exercise_induced_angina</th>\n      <th>ST_depression_induced_by_exercise</th>\n      <th>peak_exercise_st_slope</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>54.438944</td>\n      <td>0.679868</td>\n      <td>3.158416</td>\n      <td>131.689769</td>\n      <td>246.693069</td>\n      <td>0.148515</td>\n      <td>0.990099</td>\n      <td>149.607261</td>\n      <td>0.326733</td>\n      <td>1.039604</td>\n      <td>1.600660</td>\n      <td>0.937294</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>9.038662</td>\n      <td>0.467299</td>\n      <td>0.960126</td>\n      <td>17.599748</td>\n      <td>51.776918</td>\n      <td>0.356198</td>\n      <td>0.994971</td>\n      <td>22.875003</td>\n      <td>0.469794</td>\n      <td>1.161075</td>\n      <td>0.616226</td>\n      <td>1.228536</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>29.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>94.000000</td>\n      <td>126.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>71.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>48.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>120.000000</td>\n      <td>211.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>133.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>56.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>130.000000</td>\n      <td>241.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>153.000000</td>\n      <td>0.000000</td>\n      <td>0.800000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>61.000000</td>\n      <td>1.000000</td>\n      <td>4.000000</td>\n      <td>140.000000</td>\n      <td>275.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>166.000000</td>\n      <td>1.000000</td>\n      <td>1.600000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>77.000000</td>\n      <td>1.000000</td>\n      <td>4.000000</td>\n      <td>200.000000</td>\n      <td>564.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>202.000000</td>\n      <td>1.000000</td>\n      <td>6.200000</td>\n      <td>3.000000</td>\n      <td>4.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hd.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TODO: While trying to convert to numeric, some rows where found with \"?\". These rows are dropped."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "hd = hd[hd[\"major_vessels_count\"]!=\"?\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "hd = pd.to_numeric(hd[\"major_vessels_count\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pandas Profile Report\n",
    "Here we create a pandas profile report and save it to the processed file. This line of code is commented out as we only need to run it once. The profile provides some good insights on the different variables and would be a good place to start next time. It was discovered as a tool half-way through the pre-processing."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "734deca4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# profile = pp.ProfileReport(hd, title=\"Profile Report of Heart Disease Dataset\")\n",
    "# profile.to_file(\"../data/processed/hd_data_profile.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1bd5e661",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# objectAttributesKey = [\"sex\", \"chest_pain_type\", \"fasting_blood_sugar\", \"resting_electrocardiographic\", \"exercise_induced_angina\", \"peak_exercise_st_slope\", \"major_vessels_count\", \"thalassemia\", \"target\"]\n",
    "# objectAttributes = {i: \"object\" for i in objectAttributesKey}\n",
    "#\n",
    "# integerAttributesKey = [\"age\", \"resting_blood_pressure\", \"cholesterol\", \"max_heart_rate_achieved\", \"ST_depression_induced_by_exercise\"]\n",
    "# integerAttributes = {i: \"float\" for i in integerAttributesKey}\n",
    "#\n",
    "# attributeTypes = objectAttributes | integerAttributes\n",
    "# hd=hd.astype(attributeTypes)\n",
    "#\n",
    "# hd.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "# hd[\"target\"] = hd[\"target\"].replace([0,1,2,3,4],[\"Healthy\", \"Sick\",\"Sick\",\"Sick\", \"Sick\"])\n",
    "\n",
    "# hd.loc[hd.target == \"2\"] = \"Sick\"\n",
    "# hd.loc[hd.target == \"3\"] = \"Sick\"\n",
    "# hd.loc[hd.target == \"4\"] = \"Sick\"\n",
    "# hd.loc[hd.target == \"1\"] = \"Healthy\"\n",
    "# hd['target'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "dtype('float64')"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hd.describe()\n",
    "hd.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "76596590",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "count    299.000000\nmean       0.672241\nstd        0.937438\nmin        0.000000\n25%        0.000000\n50%        0.000000\n75%        1.000000\nmax        3.000000\nName: major_vessels_count, dtype: float64"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hd.describe(include=\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5a9edc6b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<bound method NDFrame.head of 0      0.0\n1      3.0\n2      2.0\n3      0.0\n4      0.0\n      ... \n297    0.0\n298    0.0\n299    2.0\n300    1.0\n301    1.0\nName: major_vessels_count, Length: 299, dtype: float64>"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hd.describe(include=\"object\")\n",
    "hd.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b53d947",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Taking Care of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "124dc76f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299,)\n",
      "(299,)\n"
     ]
    }
   ],
   "source": [
    "print(hd.shape)\n",
    "hd1=hd.dropna()\n",
    "print(hd1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we have renamed our column headers and changed the column types, we will split the data into a train and test model and continue pre-processing on only the training data so as not to introduce data spill"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    },
    {
     "ename": "IndexingError",
     "evalue": "Too many indexers",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexingError\u001B[0m                             Traceback (most recent call last)",
      "Input \u001B[0;32mIn [102]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(hd_split\u001B[38;5;241m.\u001B[39mdtypes)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# hd_split.astype(float)\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[43mhd_split\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m      6\u001B[0m y \u001B[38;5;241m=\u001B[39m hd_split\u001B[38;5;241m.\u001B[39miloc[:,\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m      7\u001B[0m y \u001B[38;5;241m=\u001B[39m hd_split\u001B[38;5;241m.\u001B[39miloc[:,\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mfloat\u001B[39m)\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/Machine-Learning-Project-QM2H3y13/lib/python3.9/site-packages/pandas/core/indexing.py:961\u001B[0m, in \u001B[0;36m_LocationIndexer.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m    959\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_scalar_access(key):\n\u001B[1;32m    960\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_get_value(\u001B[38;5;241m*\u001B[39mkey, takeable\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_takeable)\n\u001B[0;32m--> 961\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_tuple\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    962\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    963\u001B[0m     \u001B[38;5;66;03m# we by definition only have the 0th axis\u001B[39;00m\n\u001B[1;32m    964\u001B[0m     axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxis \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/Machine-Learning-Project-QM2H3y13/lib/python3.9/site-packages/pandas/core/indexing.py:1458\u001B[0m, in \u001B[0;36m_iLocIndexer._getitem_tuple\u001B[0;34m(self, tup)\u001B[0m\n\u001B[1;32m   1456\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_getitem_tuple\u001B[39m(\u001B[38;5;28mself\u001B[39m, tup: \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m-> 1458\u001B[0m     tup \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_tuple_indexer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtup\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1459\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m suppress(IndexingError):\n\u001B[1;32m   1460\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_lowerdim(tup)\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/Machine-Learning-Project-QM2H3y13/lib/python3.9/site-packages/pandas/core/indexing.py:765\u001B[0m, in \u001B[0;36m_LocationIndexer._validate_tuple_indexer\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m    761\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_validate_tuple_indexer\u001B[39m(\u001B[38;5;28mself\u001B[39m, key: \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mtuple\u001B[39m:\n\u001B[1;32m    762\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    763\u001B[0m \u001B[38;5;124;03m    Check the key for valid keys across my indexer.\u001B[39;00m\n\u001B[1;32m    764\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 765\u001B[0m     key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_key_length\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    766\u001B[0m     key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_expand_ellipsis(key)\n\u001B[1;32m    767\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, k \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(key):\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/Machine-Learning-Project-QM2H3y13/lib/python3.9/site-packages/pandas/core/indexing.py:812\u001B[0m, in \u001B[0;36m_LocationIndexer._validate_key_length\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m    810\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m IndexingError(_one_ellipsis_message)\n\u001B[1;32m    811\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_key_length(key)\n\u001B[0;32m--> 812\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m IndexingError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mToo many indexers\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    813\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m key\n",
      "\u001B[0;31mIndexingError\u001B[0m: Too many indexers"
     ]
    }
   ],
   "source": [
    "hd_split = hd\n",
    "# hd[\"target\"] = hd[\"target\"].replace([\"Healthy\", \"Sick\"],[0,1])\n",
    "print(hd_split.dtypes)\n",
    "# hd_split.astype(float)\n",
    "X = hd_split.iloc[:,-1]\n",
    "y = hd_split.iloc[:,-1]\n",
    "y = hd_split.iloc[:,-1].astype(float)\n",
    "# print(X.shape, y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "# creating hd_train to be used for exploratory data analysis\n",
    "hd_train, hd_test = train_test_split(hd, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "71502c66",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Finding Outliers\n",
    "\n",
    "We will take a look at the 1.5*IQR and visualize with boxplots to see if there are any outliers we need to deal with.\n",
    "Boxplots will be plotted against our tagert value of healthy and unhealthy to start seeing if there is any correlation between our numerical attributes and target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set(rc = {'figure.figsize':(5,5)})\n",
    "sns.set_context(rc={\"font.size\":16,\"axes.titlesize\":18,\"axes.labelsize\":16})\n",
    "for i in integerAttributesKey:\n",
    "    plt.figure(i)\n",
    "    sns.boxplot(x=\"target\", y=i, data=hd_train, orient=\"v\", palette=\"Set3\", flierprops = dict(marker=\"x\", markersize = 4))\n",
    "    plt.suptitle(f\"Boxplot of {i} vs Target\")\n",
    "\n",
    "    # Print IQR and ceiling floor values\n",
    "    Q1 = hd_train[i].quantile(0.25)\n",
    "    Q3 = hd_train[i].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    low_outliers = Q1 - 1.5 * IQR\n",
    "    upper_outliers = Q3 + 1.5 * IQR\n",
    "    number_of_outliers = hd_train[i][(hd_train[i] < low_outliers) | (hd_train[i] > upper_outliers)].count()\n",
    "    print(f'{i} lower and upper 1.5*IQR and values outside this range is: \\n lower: {low_outliers}\\tupper: {upper_outliers} \\nvalue count: {number_of_outliers}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Outlier Decision\n",
    "Based on these results, there are not many outlier values. Given the box plot visualizations, the outliers are not deemed to be noise and will not be removed from the dataset.\n",
    "\n",
    "We can also see a potential that:\n",
    "- age and resting heart rate seem correlated with heart disease\n",
    "- higher max heart rate is associated with individuals without heart diseases\n",
    "- cholesterol doesn't have a significant impact\n",
    "\n",
    "# Initial Visualizations\n",
    "We can take a look at some visualizations to see if there are some interesting trends or hypothesis we can test. This will also give us an idea of which models we might want to test and which attributes we expect to have the most impact on our target.\n",
    "\n",
    "From looking at the boxplots, we also know that our data is in different ranges and we will need to consider applying a normalization depending on the model we choose. We will do that later once we know which models we will try to run.\n",
    "\n",
    "\n",
    "## Continuous Variables\n",
    "We'll add some scatterplots and histograms to continue analyzing our numerical data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(4,4,figsize=(26,20))\n",
    "# We will not plot country because it has too many categories.\n",
    "for index, columnName in enumerate(hd_train.columns[1:]):\n",
    "    ax = axes.reshape(-1)[index]\n",
    "    if hd_train[columnName].dtype.kind == 'O':\n",
    "        a = sns.countplot(x=columnName,data=hd_train,ax=ax)\n",
    "    else:\n",
    "        b = sns.histplot(x=columnName,data=hd_train,ax=ax)\n",
    "    t = ax.set_title(columnName)\n",
    "plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set_context(rc={\"font.size\":16,\"axes.titlesize\":12,\"axes.labelsize\":12})\n",
    "pairwise_viz = sns.PairGrid(hd_train, vars=integerAttributesKey, hue=\"target\", diag_sharey=False, corner=True)\n",
    "pairwise_viz.map_lower(sns.scatterplot, alpha=0.4)\n",
    "pairwise_viz.map_diag(sns.histplot)\n",
    "pairwise_viz.add_legend()\n",
    "pairwise_viz.fig.subplots_adjust(top=0.9)\n",
    "pairwise_viz.fig.suptitle(\"Pairwise Relationship Plots of Numerical Values - Target\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It looks like there are a lot of individuals that had no ST depression induced by exercise (value of 0). It might be interesting to see how the target responds to those and without this value present. Let's dive into that.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.catplot(x=\"target\", y=\"ST_depression_induced_by_exercise\", kind=\"swarm\", hue=\"sex\", data=hd_train[hd_train[\"ST_depression_induced_by_exercise\"] != 0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.countplot(x=\"target\", hue=\"sex\", data=hd_train[hd_train[\"ST_depression_induced_by_exercise\"] == 0.0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It looks like non-zero levels of ST depression induced by exercise are more prevalent in males, and those that have higher values have a greater tendency to have heart disease. We can also see that males with zero values have a greater chance of heart disease. Let's see what the absolute impact of sex on heart disease is."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.histplot(x=\"target\", stat=\"density\", hue=\"sex\", data=hd_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It looks like our data is generally showing that males are more likely to be sick than females."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "We can take a look to see if we see any other interesting differences between males and females.\n",
    "Although nothing jumps out at us, it does look like there is a bit of a \"binning\" of data for the resting blood pressure. We won't do anything about it at the moment. This may be a result of different methods of collecting blood pressure that resulted in a different level of precision."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pairwise_viz = sns.PairGrid(hd_train, vars=integerAttributesKey, hue=\"sex\", diag_sharey=False, corner=True)\n",
    "pairwise_viz.map_lower(sns.scatterplot, alpha=0.4)\n",
    "pairwise_viz.map_diag(sns.histplot)\n",
    "pairwise_viz.add_legend()\n",
    "pairwise_viz.fig.subplots_adjust(top=0.9)\n",
    "pairwise_viz.fig.suptitle(\"Pairwise Relationship Plots of Numerical Values - Sex\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,8))\n",
    "sns.set_theme(style=\"white\")\n",
    "corr = hd_train.corr()\n",
    "heatmap = sns.heatmap(corr, annot=True, cmap=\"coolwarm\", fmt='.1g')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set(rc = {'figure.figsize':(5,5)})\n",
    "sns.set_context(rc={\"font.size\":14,\"axes.titlesize\":10,\"axes.labelsize\":10})\n",
    "for i in objectAttributes:\n",
    "    plt.figure(i)\n",
    "    sns.catplot(x=i, kind=\"count\", hue=\"sex\", col=\"target\", data=hd_train)\n",
    "    plt.suptitle(f\"Boxplot of {i} vs Target\")\n",
    "    plt.subplots_adjust(top=0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualization\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.countplot('sex', data=hd_train, hue='target')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fast Visualization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Description of the attributes\n",
    "1. age - age in years\n",
    "\n",
    "2. sex - (1 = male; 0 = female)\n",
    "\n",
    "3. cp - chest pain type\n",
    "\n",
    "0: Typical angina: chest pain related decrease blood supply to the heart\n",
    "\n",
    "1: Atypical angina: chest pain not related to heart\n",
    "\n",
    "2: Non-anginal pain: typically esophageal spasms (non heart related)\n",
    "\n",
    "3: Asymptomatic: chest pain not showing signs of disease\n",
    "\n",
    "4. trestbps - resting blood pressure (in mm Hg on admission to the hospital) anything above 130-140 is typically cause for concern\n",
    "\n",
    "5. chol - serum cholestoral in mg/dl\n",
    "\n",
    "serum = LDL + hd_trainL + .2 * triglycerides\n",
    "\n",
    "above 200 is cause for concern\n",
    "\n",
    "6. fbs - (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n",
    "\n",
    "'>126' mg/dL signals diabetes\n",
    "\n",
    "7. restecg - resting electrocardiographic results\n",
    "\n",
    "0: Nothing to note\n",
    "\n",
    "1: ST-T Wave abnormality\n",
    "\n",
    "can range from mild symptoms to severe problems\n",
    "\n",
    "signals non-normal heart beat\n",
    "\n",
    "2: Possible or definite left ventricular hypertrophy\n",
    "\n",
    "Enlarged heart's main pumping chamber\n",
    "\n",
    "8. thalach - maximum heart rate achieved\n",
    "\n",
    "9. exang - exercise induced angina (1 = yes; 0 = no)\n",
    "\n",
    "10. oldpeak - ST depression induced by exercise relative to rest looks at stress of heart during excercise unhealthy heart will stress more\n",
    "\n",
    "11. slope - the slope of the peak exercise ST segment\n",
    "\n",
    "0: Upsloping: better heart rate with excercise (uncommon)\n",
    "\n",
    "1: Flatsloping: minimal change (typical healthy heart)\n",
    "\n",
    "2: Downslopins: signs of unhealthy heart\n",
    "\n",
    "12. ca - number of major vessels (0-3) colored by flourosopy\n",
    "\n",
    "colored vessel means the doctor can see the blood passing through\n",
    "\n",
    "the more blood movement the better (no clots)\n",
    "\n",
    "13. thal - thalium stress result\n",
    "\n",
    "1,3: normal\n",
    "\n",
    "6: fixed defect: used to be defect but ok now\n",
    "\n",
    "7: reversable defect: no proper blood movement when exercising\n",
    "\n",
    "14. target - have disease or not (1=yes, 0=no) (= the predicted attribute)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "70ce8714",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It looks like ST_depression_induced_by_exercise has lots of 0's. Let's explore that to see how many."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9dc487",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print((hd_train['ST_depression_induced_by_exercise'] == 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.histplot(x=\"ST_depression_induced_by_exercise\",data=hd_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Based on research for what ST depression induced by exercise is, we find that it is a measure of change in an ECG reading after exercise. Subjects with a \"0\" are subjects that did not have any ST depression, where subjects with a non-zero value had some ST depression present. Thus, the \"0\" values will not be removed and will be considered correct. It could be interesting to come back and bin the data into a \"yes/no\" categorical for use in model building."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = 'Random Forest Classfier'\n",
    "rf = RandomForestClassifier(n_estimators=20, random_state=42,max_depth=5)\n",
    "rf.fit(X_train,y_train)\n",
    "rf_predicted = rf.predict(X_test)\n",
    "rf_conf_matrix = confusion_matrix(y_test, rf_predicted)\n",
    "rf_acc_score = accuracy_score(y_test, rf_predicted)\n",
    "print(\"confusion matrix\")\n",
    "print(rf_conf_matrix)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy of Random Forest:\",rf_acc_score*100,'\\n')\n",
    "print(classification_report(y_test,rf_predicted))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}