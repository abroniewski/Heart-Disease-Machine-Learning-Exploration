{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import mean,std\n",
    "from scipy.stats import randint\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report,mean_squared_error\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold,train_test_split,cross_val_score,cross_validate"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "X= pd.read_csv('../data/processed/X_train', header=0, index_col=0)\n",
    "X_final_test = pd.read_csv('../data/processed/X_final_test', header=0, index_col=0)\n",
    "y = pd.read_csv('../data/processed/y_train', header=0, index_col=0)\n",
    "y_final_test = pd.read_csv('../data/processed/y_final_test', header=0, index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature Scaling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "#\n",
    "# sc = StandardScaler()\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# X_test = sc.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Decision Tree Model Building"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23  5]\n",
      " [ 7 13]]\n",
      "Accuracy: 75.0 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.82      0.79        28\n",
      "           1       0.72      0.65      0.68        20\n",
      "\n",
      "    accuracy                           0.75        48\n",
      "   macro avg       0.74      0.74      0.74        48\n",
      "weighted avg       0.75      0.75      0.75        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#without hyperparameter tuning\n",
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred)*100,'%')\n",
    "print(classification_report(y_test,y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7708333333333334\n"
     ]
    }
   ],
   "source": [
    "#with hyperparameter tuning\n",
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cross Fold Validation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7304093567251463\n"
     ]
    }
   ],
   "source": [
    "#cross fold validation without hyper tuning\n",
    "cv = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "clf = DecisionTreeClassifier()\n",
    "print(cross_val_score(clf, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1).mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "              F-score (cv) Precision (cv) Recall (cv) Accuracy (cv)\nDecision Tree     0.733612         0.7539    0.749727      0.746491",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>F-score (cv)</th>\n      <th>Precision (cv)</th>\n      <th>Recall (cv)</th>\n      <th>Accuracy (cv)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Decision Tree</th>\n      <td>0.733612</td>\n      <td>0.7539</td>\n      <td>0.749727</td>\n      <td>0.746491</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cross fold validation with hyper tuning\n",
    "results_df = pd.DataFrame(index=['Decision Tree'],\n",
    "                          columns=['F-score (cv)', 'Precision (cv)','Recall (cv)', 'Accuracy (cv)'])\n",
    "cv = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
    "results=pd.DataFrame(cross_validate(clf, X_train, y_train, scoring = [ 'f1_macro', 'precision_macro', 'recall_macro', 'accuracy'], cv=cv, n_jobs=-1))\n",
    "results_df.loc['Decision Tree',:] = results[['test_f1_macro',\n",
    "       'test_precision_macro', 'test_recall_macro','test_accuracy']].mean().values\n",
    "\n",
    "results_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hyperparameter tuning of DT using RandomizedSearchCV\n",
    "In RandomizedSearchCV,not all hyperparameter values are used. Instead, a fixed number of hyperparameters are sampled from specified probability distributions.The following hyperparameter are chosen for tuning:\n",
    "\n",
    "\"max_depth\":[3,None]\n",
    "max_depth: The maximum depth of the tree.The higher value of maximum depth causes overfitting, and a lower value causes underfitting. So, we set 3 to none.\n",
    "\"min_samples_leaf\":randint(1,20),\n",
    "min_samples_leaf: The minimum number of samples required to be at a leaf node. We set random value to be chosen from 1 to 20.\n",
    "\"criterion\":[\"gini\",\"entropy\"]\n",
    "criterion: The function to measure the quality of a split. We set both gini and entropy to choose the best one for this decision tree model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.825605 using {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 9}\n",
      "[[24  4]\n",
      " [ 6 14]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#paramters setup for tuning\n",
    "param={\"max_depth\":[3,None],\"min_samples_leaf\":randint(1,20),\"criterion\":[\"gini\",\"entropy\"]}\n",
    "#\"min_samples_split\":randint(1,40)\n",
    "#\"min_samples_leaf\":randint(1,20)\n",
    "\n",
    "#instatiate decision tree classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "#instatiate RandomizedSearchCV\n",
    "clf_cv=RandomizedSearchCV(clf,param,cv=5)\n",
    "\n",
    "#fitting the model\n",
    "clf_cv.fit(X_train,y_train)\n",
    "\n",
    "#print the tuned parameters and score\n",
    "print(\"Best: %f using %s\" % (clf_cv.best_score_.mean(), clf_cv.best_params_))\n",
    "means = clf_cv.cv_results_['mean_test_score']\n",
    "stds = clf_cv.cv_results_['std_test_score']\n",
    "params = clf_cv.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "#printing the confusion metrix\n",
    "y_pred=clf_cv.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Building the model using Bagging Classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8148148148148148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\PycharmProjects\\Heart-Disease-Machine-Learning-Exploration\\venv\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:719: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bagging_model = BaggingClassifier(\n",
    "base_estimator=DecisionTreeClassifier(),\n",
    "n_estimators=100,\n",
    "max_samples=0.8,\n",
    "bootstrap=True,\n",
    "oob_score=True,\n",
    "random_state=0\n",
    ")\n",
    "bagging_model.fit(X_train,y_train)\n",
    "print(bagging_model.oob_score_)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}